{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN + LSTM\n",
    "##### I really hope I can wirte this as an academic paper, but also really have no time, so I just list all the key engineering steps below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1  Business Scenario\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   As a fintech company, one of the most important thing we need to be very careful and sentitive is credit risks evaluation.  Imagine when a coffee shop onwer come to borrow money, though his personal record is pretty, but do we need to also consider coffee industry holistic repayment performance in this customer's geographic area?  The answer is yes, cause marco effect do exist and can be model by this model I build up. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2  Problem & Solution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thus, I defined our problem as a temporal-spatial time sereis forecasting model. Traditional time series forecasting model, like ARIMA, MA, Facebook Prophet, Linear regression, Boosting Tree Regression, only take temporal feature into account, but igonre geographic attribute behind and thus missed a very valueable peice of information.\n",
    "\n",
    "To solve this limitation, I borrow idea from several state-of-the-art academic papers published from the coorperation between Uber / DIDI(Chinese Uber) and top tier AI lab in academic feild. \n",
    "\n",
    "In general, assume readers of this arcticle have basic machine learning and deep learning background, it is not surprisingly I treat geo-location with its geo-neighbours at a time as an image and use CNN to extract high level spatial features from input data, and then use which as LSTM input corresponding to the time step it belongs to, for making prediction.\n",
    "\n",
    "As I forementioned, my model will forecasting overall repayment performance according to the given fishnet_id, industry and time t. Before we dive into model, I will explain how I prepare our data to help you understand fishnet, industry and every input."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"files/Model.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3  Input : Data Preparation, preprocessing "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3.1 Geographic Index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see the picture above, I first use ARCGIS software to do geographic index. \n",
    "\n",
    "Specifically, I first use 'Fishnet' toolkit to make Autralia consists of around 2 millons of 2km by 2km grid which are stored their index as fishnet id and 4 pair of coordinators to represent this squre. \n",
    "\n",
    "A tips here is, the size of single grid can be determined by your own situation, in this project, by setting it to 2km, I can get significant inprovement on performance, thus, I have not use this as hyper parameter. But in the future, I will tune this hyper parameter as well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3.2 Geographic neighbours"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To model the spatial information, I also use the historical information of target grid's neighbours as input. Here, you can imagine each input to Convoluton Neural Nets(CNN) is a 7 by 7 image, with 48 geo neighbours of target grid which located in the center.\n",
    "\n",
    "In one words, CNN will extracts high level features and models the spatial correlations among these grids."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3.3 Dataset construction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In traditional time series forecasting, we only use targets' historical data as input to make prediction. For example, if you want to predict the sellings of next month, what you input is past few months' selling data. \n",
    "\n",
    "Here however, I use three different kind of information to fill into above 7 by 7 image and then stack them together (like image channels) to build up our input dataset.\n",
    "\n",
    "Given a target grid with its 48 neighbours, the first channel is repayment performance(also our predicting target). For a give month and insudtry, I calculate the overall repayment performance within these 49 fishnet grids and use this 7 by 7 array as one channel of our input.  Then I follow the above way and fill other two 7 by 7 channgel with density and overall dishounours. \n",
    "\n",
    "Here, my aim is not introduce our model, but try to inspire reader to do their own project, so I will not discuss many details of what our own data. Just keep in mind that, you can define whatever data you want to suit your scenario.\n",
    "\n",
    "So, finally, I use 7*7*3 np ndarray to represent this 'image' data at one time, while our target is centre grid's repayment performance at predicting month. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4  Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Models is not very complicate, each input data, as described in above, will be outputted as a falttened features by CNN, which will then as input to LSTM model, like traiditional time series forecasting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  1.4.1 Model\n",
    "I attch my code below as reference,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cnn_on_lstm_rms_model(CONV2D_1_DEPTH, CONV2D_2_DEPTH, CNN_DP, #CNN archi related\n",
    "                          LSTM_DP, LSTM_UNITS, #LSTM archi related# RMSprop related\n",
    "                          inputshapes, loss_fnc):\n",
    "    model = Sequential()\n",
    "    #add two time-distributed convolutional layers for feature extraction\n",
    "    model.add(TimeDistributed(Conv2D(CONV2D_1_DEPTH, (3, 3), activation='relu'), input_shape = inputshapes))\n",
    "    #model.add(TimeDistributed(Conv2D(16, (4, 4), activation='relu')))\n",
    "    model.add(TimeDistributed(Conv2D(CONV2D_2_DEPTH, (5, 5), activation='relu')))\n",
    "\n",
    "\n",
    "    # extract features and dropout \n",
    "    model.add(TimeDistributed(Flatten()))\n",
    "    model.add(Dropout(CNN_DP))\n",
    "    #print(123123123)\n",
    "    # input to LSTM\n",
    "    model.add(LSTM(LSTM_UNITS, return_sequences=True, dropout=LSTM_DP)) #input_shape=(5, 512), \n",
    "    #print(123123123)\n",
    "    # classifier with sigmoid activation for multilabel\n",
    "    model.add(Dense(1, activation='tanh'))\n",
    "    #model.add(TimeDistributed(Dense(1, activation='tanh')))\n",
    "\n",
    "    # compile the model with binary_crossentropy loss for multilabel\n",
    "    #Rmsprop = keras.optimizers.RMSprop(lr=RMSprop_LR, rho=RMSprop_RHO, \n",
    "    #                                   epsilon=None, decay=RMSprop_DECAY)\n",
    "    #model.compile(optimizer= Rmsprop, loss = loss_fnc)\n",
    "    #keras.optimizers.RMSprop(lr=0.001, rho=0.9, epsilon=None, decay=0.0)\n",
    "    model.compile(optimizer= 'rmsprop', loss = mape_loss)\n",
    "    # look at the params before training\n",
    "    #model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.4.2 Hyper Parameters List\n",
    "\n",
    "In general, there are many hyperparameter to tune if you have enough computing resources and time. Here, I will breifly explain what is our hyperparaments and how I choose specific value for them in the list below,\n",
    "\n",
    "| Hyperparameter | Chosen Value | Reason | \n",
    "| --- | --- | --- |\n",
    "| CNN 1st filter size  | 3 | our fishnet grid is 2km * 2km, empirically, we make linear combination of features within range of 6km * 6km will enough|\n",
    "| CNN 2nd filter size  | 5 | similar to above one, but we can consider more wider range based on extracted high level features |\n",
    "| CNN 1st DEPTH | 64 | Gird search from [32,64,128] |\n",
    "| CNN 2nd DEPTH | 64 | Gird search from [32,64,128] |\n",
    "| CNN 1st Active Funtion | relu | avoid gradient vanish |\n",
    "| CNN 2nd Active Funtion | relu | avoid gradient vanish |\n",
    "| CNN Drop Out | 0.1 | Gird search from [0.1,0.3,0.5] |\n",
    "| LSTM Unit | 64 | Gird search from [32,64,128] |\n",
    "| LSTM Drop Out | 0.1 | Gird search from [0.1,0.3,0.5] |\n",
    "| LSTM Active Function | tanh | just the default setting of LSTM, especially LSTM not very deep  |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Moreover, in terms of optimzed function, we choose the RMSprop to salute to G.Hinton :) Specifically, it is because our data is sparse and also means it is kind of 'stable', for the sake of speeding up the learning process, we choose algorithms which can employ adptive learning rate based on the updated gradient in each round. Obviously, Adagrad, Adadelta, RMSprop, Adam are common choices. RMSProp and Adadelta are almost the same, excpet Adadelta use RMS of parameters, rather than RMS of initial learning rate, to update weights. There is not obvious different when compare Adam and RMSprop ,thus, we finally choose RMSprop."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5  Comparison among different models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I did a grid search on all hyper parameters of my CNN+LSTM model, and choose the best one to compare with other three models, which are xgboost regression, Moving average and ARIMA. The comparison result can be seen as below(I only choose 3 main industries),"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"files/compare.png\" alt=\"Drawing\" style=\"width: 350px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, as we can see MAPE and RMSE compare, my model outperform other three."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.6  Comparison inside differet channel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.6.1 comparison of MAPE and RMSE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I also did an additional comparison among utilizing 1 channgel only, utilizing 2 channels and utilizing 3 channels. This is also new idea to all reference paper I surveyed and expriment prove that using 3 channel is the best to our scenario. The result can be seen as below,"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|Industry_ID | Channel(s) | MAPE | RMSE |\n",
    "| --- | --- | --- |\n",
    "| 1 | 1 | 2.99 |0.023 |\n",
    "| 1 | 2 | 2.71 |0.021 |\n",
    "| 1 | 3 | 2.67 |0.019 |\n",
    "\n",
    "|Industry_ID | Channel(s) | MAPE | RMSE |\n",
    "| --- | --- | --- |\n",
    "| 2 | 1 | 2.57 |0.02 |\n",
    "| 2 | 2 | 2.31 |0.018 |\n",
    "| 2 | 3 | 2.22 |0.017 |\n",
    "\n",
    "|Industry_ID | Channel(s) | MAPE | RMSE |\n",
    "| --- | --- | --- |\n",
    "| 3 | 1 | 3.74 |0.026 |\n",
    "| 3 | 2 | 3.40 |0.024 |\n",
    "| 3 | 3 | 3.30 |0.022 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In all of these three main industries, model with 3 channel input data can beats others - I use the same parameter and hyper parameters for all these models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.6.2 comparison of error disstribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cause majority of our target value is stable, the MAPE and RMSE cannot fully demonstrate the capbility of capturing the performance when predicting some sample with relatively smaller target value.\n",
    "\n",
    "Thus, I defined a metric named '085 erros distribution', which means choose all the sample with true repayment performance under 0.85 and then count how many times the absolute value of predicting value minus true value less than or equal to 0.1.\n",
    "\n",
    "As Deep learning models have ramdom parameters which lead to different results, so we run each of these 3 different models 30 times and plot the distributuon of '085 erros distribution'\n",
    "\n",
    "The comparasion can be seen as below,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table><tr><td><img src='hos1.png'></td><td><img src='hos2.png'></td><td><img src='hos3.png'></td></tr></table><figcaption>Industry_1: 1, 2 and 3 channel</figcaption>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table><tr><td><img src='ret1.png'></td><td><img src='ret2.png'></td><td><img src='ret3.png'></td></tr></table><figcaption>Industry_2: 1, 2 and 3 channel</figcaption>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table><tr><td><img src='bud1.png'></td><td><img src='bud2.png'></td><td><img src='bud3.png'></td></tr></table><figcaption>Industry_3: 1, 2 and 3 channel</figcaption>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, HTML, display\n",
    "from glob import glob\n",
    "#imagesList=''.join( [\"<img style='width: 120px; margin: 0px; float: left; border: 1px solid black;' src='%s' />\" % str(s) \n",
    "#                     for s in sorted(glob('map_*.png')) ])\n",
    "display(HTML(\"<table><tr><td><img src='hos1.png'></td><td><img src='hos2.png'></td><td><img src='hos3.png'></td></tr></table><figcaption>Industry_1: 1, 2 and 3 channel</figcaption>\"))\n",
    "display(HTML(\"<table><tr><td><img src='ret1.png'></td><td><img src='ret2.png'></td><td><img src='ret3.png'></td></tr></table><figcaption>Industry_2: 1, 2 and 3 channel</figcaption>\"))\n",
    "display(HTML(\"<table><tr><td><img src='bud1.png'></td><td><img src='bud2.png'></td><td><img src='bud3.png'></td></tr></table><figcaption>Industry_3: 1, 2 and 3 channel</figcaption>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apparently, performance of 3 channel in this metric still the best. \n",
    "\n",
    "----------- TBC"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
