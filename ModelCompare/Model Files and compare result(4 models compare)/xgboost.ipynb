{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/michael.zhang/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pandas import datetime\n",
    "from matplotlib import pyplot\n",
    "from statsmodels.tsa.arima_model import ARIMA\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "from pandas.tools.plotting import autocorrelation_plot\n",
    "import xgboost as xgb\n",
    "import six\n",
    "from six.moves import cPickle as cpik\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mape_loss(y_true, y_pred):\n",
    "    diff = K.abs((y_true - y_pred) / K.clip(K.abs(y_true),\n",
    "                                            K.epsilon(),\n",
    "                                            None))\n",
    "    return 100. * K.mean(diff, axis=-1)\n",
    "\n",
    "def mape(y_p, y):\n",
    "    y[y == 0] = 0.01\n",
    "    diff = np.abs((y_p - y) / y)\n",
    "    #print(diff)\n",
    "    return 100. * np.mean(diff)\n",
    "\n",
    "# RMSE loss for calculate test result.\n",
    "def rmse(y_p, y):\n",
    "    diff = np.sqrt((y_p - y)**2)# np.sum()\n",
    "    return np.mean(diff)  \n",
    "\n",
    "\n",
    "def build_dl_dataset_by_ts(df, ts):\n",
    "    '''\n",
    "    Build up a (data_size * 11 * 7 * 7 * 2) dataset for both traning and testing\n",
    "    \n",
    "    Input\n",
    "    df: a dateframe\n",
    "    ts: time_steps, use how many previous time frame to predict the next one, e.g., if it is 11, then use the\n",
    "        previous 11 date to predict current 1.\n",
    "    \n",
    "    Output\n",
    "    Training set and testing set\n",
    "    \n",
    "    '''\n",
    "    fids = df['FishnetID'].unique().tolist()\n",
    "    #print(fids)\n",
    "    X_train = []\n",
    "    Y_train = []\n",
    "    X_test = []\n",
    "    Y_test = []\n",
    "    \n",
    "    for fid in fids:\n",
    "        df_current = df[df['FishnetID'] == fid].reset_index(drop = True) #original dataset has been ordered by time.\n",
    "        df_current_len = df_current.shape[0] # overall length of current data \n",
    "        if (df_current_len - ts - 1)>0:\n",
    "            for i in range(df_current_len - ts - 1):\n",
    "                # current slice of input data\n",
    "                X_train_cur = []\n",
    "                Y_train_cur = []\n",
    "                # append every X by time steps\n",
    "                for x_v in df_current['neighbours_index_image'].iloc[i : (i+ts)].values:\n",
    "                    X_train_cur.append(x_v)\n",
    "                    #print(np.array(X_cur).shape)    \n",
    "                X_train.append(np.array(X_train_cur))  \n",
    "                # append very Y by time steps\n",
    "                for y_v in df_current['PerformanceTarget'].iloc[i+1 : (i+ts+1)].values:\n",
    "                    Y_train_cur.append(y_v)\n",
    "                Y_train.append(np.array(Y_train_cur))\n",
    "            \n",
    "            for i in range(df_current_len - ts - 1, df_current_len - ts):\n",
    "                # current slice of input data\n",
    "                X_test_cur = []\n",
    "                Y_test_cur = []\n",
    "                # append every X by time steps\n",
    "                for x_v in df_current['neighbours_index_image'].iloc[i : (i+ts)].values:\n",
    "                    X_test_cur.append(x_v)\n",
    "                    #print(np.array(X_cur).shape)\n",
    "                X_test.append(np.array(X_test_cur))  \n",
    "                # append very Y by time steps\n",
    "                for y_v in df_current['PerformanceTarget'].iloc[i+1 : ].values:\n",
    "                    Y_test_cur.append(y_v)\n",
    "                Y_test.append(np.array(Y_test_cur))\n",
    "        else:\n",
    "            for i in range(df_current_len - ts):\n",
    "                # current slice of input data\n",
    "                X_cur = []\n",
    "                Y_cur = []\n",
    "                # append every X by time steps\n",
    "                for x_v in df_current['neighbours_index_image'].iloc[i : (i+ts)].values:\n",
    "                    X_cur.append(x_v)\n",
    "                    #print(np.array(X_cur).shape)    \n",
    "                X_train.append(np.array(X_cur))\n",
    "                X_test.append(np.array(X_cur))  \n",
    "                # append very Y by time steps\n",
    "                for y_v in df_current['PerformanceTarget'].iloc[i+1 : (i+ts+1)].values:\n",
    "                    Y_cur.append(y_v)\n",
    "                Y_train.append(np.array(Y_cur))\n",
    "                Y_test.append(np.array(Y_cur))      \n",
    "    return (X_train, Y_train, X_test, Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hospitality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4459,) (7, 7, 2)\n"
     ]
    }
   ],
   "source": [
    "hos_df = pd.read_csv('3_hospitality_13months.csv').iloc[:, 1:8]\n",
    "\n",
    "neighbours_index_image_arys = cpik.load(open(\"3_hospitality_13months.pkl\", \"rb\" ))\n",
    "hos_df['neighbours_index_image'] = neighbours_index_image_arys.tolist()\n",
    "hos_df['neighbours_index_image'] = hos_df['neighbours_index_image'].apply(lambda x : np.array(x))\n",
    "print(hos_df['neighbours_index_image'].shape, hos_df['neighbours_index_image'].iloc[0].shape)\n",
    "ts = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build up dateset\n",
    "X_train, Y_train, X_test, Y_test= build_dl_dataset_by_ts(hos_df, ts)\n",
    "X_train = np.array(X_train)\n",
    "X_train= np.nan_to_num(X_train)\n",
    "\n",
    "Y_train = np.array(Y_train)\n",
    "Y_train = Y_train.reshape(Y_train.shape[0],Y_train.shape[1],1)\n",
    "Y_train= np.nan_to_num(Y_train)\n",
    "\n",
    "\n",
    "X_test = np.array(X_test)\n",
    "X_test= np.nan_to_num(X_test)\n",
    "\n",
    "Y_test = np.array(Y_test)\n",
    "Y_test = Y_test.reshape(Y_test.shape[0],Y_test.shape[1],1)\n",
    "Y_test= np.nan_to_num(Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3087, 3, 7, 7, 2) (3087, 3, 1) (343, 3, 7, 7, 2) (343, 3, 1)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, Y_train.shape, X_test.shape, Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16.835024493704356\n",
      "0.11322696094999105\n",
      "16.592409854553104\n",
      "0.10986252030081933\n"
     ]
    }
   ],
   "source": [
    "# flatten features\n",
    "X_train_flat = X_train.reshape(3087, 3*7*7*2)\n",
    "Y_train_flat = Y_train[:,-1,:]\n",
    "\n",
    "X_test_flat = X_test.reshape(343, 3*7*7*2)\n",
    "Y_test_flat = Y_test[:,-1,:]\n",
    "\n",
    "xgdmat=xgb.DMatrix(X_train_flat,Y_train_flat)\n",
    "our_params={'eta':0.6,'seed':0,'subsample':0.6,'colsample_bytree':0.7,'objective':'reg:linear','max_depth':5,'min_child_weight':0.9}\n",
    "final_gb=xgb.train(our_params,xgdmat)\n",
    "tesdmat=xgb.DMatrix(X_test_flat)\n",
    "y_pred_test =np.array(final_gb.predict(tesdmat))\n",
    "print(mape(y_pred_test, Y_test))\n",
    "print(rmse(y_pred_test, Y_test))\n",
    "\n",
    "y_pred_train =np.array(final_gb.predict(xgdmat))\n",
    "print(mape(y_pred_train, Y_test))\n",
    "print(rmse(y_pred_train, Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27.105875092448713\n",
      "0.15801587674588027\n"
     ]
    }
   ],
   "source": [
    "print(mape(y_pred_test, Y_test))\n",
    "print(rmse(y_pred_test, Y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4212,), (7, 7, 2))"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ret_df = pd.read_csv('4_retail_13months.csv').iloc[:, 1:8]\n",
    "neighbours_index_image_arys = cpik.load(open(\"4_retail_13months.pkl\", \"rb\" ))\n",
    "ret_df['neighbours_index_image'] = neighbours_index_image_arys.tolist()\n",
    "ret_df['neighbours_index_image'] = ret_df['neighbours_index_image'].apply(lambda x : np.array(x))\n",
    "ret_df['neighbours_index_image'].shape, ret_df['neighbours_index_image'].iloc[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build up dateset\n",
    "X_train, Y_train, X_test, Y_test= build_dl_dataset_by_ts(ret_df, ts)\n",
    "X_train = np.array(X_train)\n",
    "X_train= np.nan_to_num(X_train)\n",
    "\n",
    "Y_train = np.array(Y_train)\n",
    "Y_train = Y_train.reshape(Y_train.shape[0],Y_train.shape[1],1)\n",
    "Y_train= np.nan_to_num(Y_train)\n",
    "\n",
    "\n",
    "X_test = np.array(X_test)\n",
    "X_test= np.nan_to_num(X_test)\n",
    "\n",
    "Y_test = np.array(Y_test)\n",
    "Y_test = Y_test.reshape(Y_test.shape[0],Y_test.shape[1],1)\n",
    "Y_test= np.nan_to_num(Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2916, 3, 7, 7, 2) (2916, 3, 1) (324, 3, 7, 7, 2) (324, 3, 1)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, Y_train.shape, X_test.shape, Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16.59324537420084\n",
      "0.10822414313106436\n",
      "15.84629996460275\n",
      "0.099890106135536\n"
     ]
    }
   ],
   "source": [
    "# flatten features\n",
    "X_train_flat = X_train.reshape(2916, 3*7*7*2)\n",
    "Y_train_flat = Y_train[:,-1,:]\n",
    "\n",
    "X_test_flat = X_test.reshape(324, 3*7*7*2)\n",
    "Y_test_flat = Y_test[:,-1,:]\n",
    "\n",
    "xgdmat=xgb.DMatrix(X_train_flat,Y_train_flat)\n",
    "our_params={'eta':0.6,'seed':0,'subsample':0.6,'colsample_bytree':0.7,'objective':'reg:linear','max_depth':5,'min_child_weight':0.9}\n",
    "final_gb=xgb.train(our_params,xgdmat)\n",
    "tesdmat=xgb.DMatrix(X_test_flat)\n",
    "y_pred_test =np.array(final_gb.predict(tesdmat))\n",
    "print(mape(y_pred_test, Y_test))\n",
    "print(rmse(y_pred_test, Y_test))\n",
    "\n",
    "y_pred_train =np.array(final_gb.predict(xgdmat))\n",
    "print(mape(y_pred_train, Y_test))\n",
    "print(rmse(y_pred_train, Y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4498,), (7, 7, 2))"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bud_df = pd.read_csv('1_building_13months.csv').iloc[:, 1:8]\n",
    "neighbours_index_image_arys = cpik.load(open(\"1_building_13months.pkl\", \"rb\" ))\n",
    "bud_df['neighbours_index_image'] = neighbours_index_image_arys.tolist()\n",
    "bud_df['neighbours_index_image'] = bud_df['neighbours_index_image'].apply(lambda x : np.array(x))\n",
    "bud_df['neighbours_index_image'].shape, bud_df['neighbours_index_image'].iloc[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build up dateset\n",
    "X_train, Y_train, X_test, Y_test= build_dl_dataset_by_ts(bud_df, ts)\n",
    "X_train = np.array(X_train)\n",
    "X_train= np.nan_to_num(X_train)\n",
    "\n",
    "Y_train = np.array(Y_train)\n",
    "Y_train = Y_train.reshape(Y_train.shape[0],Y_train.shape[1],1)\n",
    "Y_train= np.nan_to_num(Y_train)\n",
    "\n",
    "\n",
    "X_test = np.array(X_test)\n",
    "X_test= np.nan_to_num(X_test)\n",
    "\n",
    "Y_test = np.array(Y_test)\n",
    "Y_test = Y_test.reshape(Y_test.shape[0],Y_test.shape[1],1)\n",
    "Y_test= np.nan_to_num(Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3114, 3, 7, 7, 2) (3114, 3, 1) (346, 3, 7, 7, 2) (346, 3, 1)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, Y_train.shape, X_test.shape, Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27.105875092448713\n",
      "0.15801587674588027\n",
      "26.611197029672468\n",
      "0.1513631337946317\n"
     ]
    }
   ],
   "source": [
    "# flatten features\n",
    "X_train_flat = X_train.reshape(3114, 3*7*7*2)\n",
    "Y_train_flat = Y_train[:,-1,:]\n",
    "\n",
    "X_test_flat = X_test.reshape(346, 3*7*7*2)\n",
    "Y_test_flat = Y_test[:,-1,:]\n",
    "\n",
    "xgdmat=xgb.DMatrix(X_train_flat,Y_train_flat)\n",
    "our_params={'eta':0.6,'seed':0,'subsample':0.6,'colsample_bytree':0.7,'objective':'reg:linear','max_depth':5,'min_child_weight':0.9}\n",
    "final_gb=xgb.train(our_params,xgdmat)\n",
    "tesdmat=xgb.DMatrix(X_test_flat)\n",
    "y_pred_test =np.array(final_gb.predict(tesdmat))\n",
    "print(mape(y_pred_test, Y_test))\n",
    "print(rmse(y_pred_test, Y_test))\n",
    "\n",
    "y_pred_train =np.array(final_gb.predict(xgdmat))\n",
    "print(mape(y_pred_train, Y_test))\n",
    "print(rmse(y_pred_train, Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
